# ìƒì„± ì‹œê°„: 2024-09-19 15:45:00 KST  
# í•µì‹¬ ë‚´ìš©: ì „ì—­ ì‹±ê¸€í†¤ ê¸°ë°˜ Chapter ì»¨í…ìŠ¤íŠ¸ ìºì‹± ë§¤ë‹ˆì € (ìºì‹œ ì§€ì†ì„± ê°œì„ )
# ìƒì„¸ ë‚´ìš©:
#   - GlobalChapterContextManager (ë¼ì¸ 15-35): ì „ì—­ ì‹±ê¸€í†¤ ìºì‹œ ë§¤ë‹ˆì €
#   - ChapterContextManager (ë¼ì¸ 40-70): ì¥ ì¡°í•©ë³„ ì»¨í…ìŠ¤íŠ¸ ìºì‹± (ì˜¬ë°”ë¥¸ ë©”ì„œë“œ ì‚¬ìš©)
#   - generate_chapter_hash (ë¼ì¸ 75-80): ì¥ ì¡°í•© í•´ì‹œ ìƒì„±  
#   - get_or_setup_context_cache (ë¼ì¸ 85-115): ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (ì‹±ê¸€í†¤ ìºì‹œ í™œìš©)
#   - query_with_cached_context (ë¼ì¸ 120-135): ìºì‹œëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì§ˆì˜ (ì˜¬ë°”ë¥¸ ë©”ì„œë“œëª…)
# ìƒíƒœ: active
# ì°¸ì¡°: chapter_context_manager_v3.py (ìºì‹œ ì§€ì†ì„± ê°œì„ )

import hashlib
import asyncio
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from pathlib import Path

class GlobalChapterContextManager:
    """ì „ì—­ ì‹±ê¸€í†¤ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ë§¤ë‹ˆì €"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GlobalChapterContextManager, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.context_cache: Dict[str, str] = {}  # {chapter_hash: session_info}
            self.context_metadata: Dict[str, dict] = {}  # ì»¨í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„°
            self.cache_ttl = 3600  # 1ì‹œê°„ TTL
            GlobalChapterContextManager._initialized = True
    
    def get_instance(self):
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        return self
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ìš©)"""
        self.context_cache.clear()
        self.context_metadata.clear()

class ChapterContextManager:
    """ì¥ ì¡°í•© ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ìºì‹± ë§¤ë‹ˆì € (ì‹±ê¸€í†¤ ìºì‹œ í™œìš©)"""
    
    def __init__(self, ai_service, logger, config_manager):
        self.ai_service = ai_service
        self.logger = logger
        self.config = config_manager
        # ì „ì—­ ìºì‹œ ë§¤ë‹ˆì € ì‚¬ìš©
        self.global_cache = GlobalChapterContextManager()
        
    @property
    def context_cache(self):
        """ì „ì—­ ìºì‹œì— ëŒ€í•œ í”„ë¡ì‹œ"""
        return self.global_cache.context_cache
    
    @property
    def context_metadata(self):
        """ì „ì—­ ë©”íƒ€ë°ì´í„°ì— ëŒ€í•œ í”„ë¡ì‹œ"""
        return self.global_cache.context_metadata

    def generate_chapter_hash(self, chapters: List[str]) -> str:
        """ì¥ ì¡°í•©ìœ¼ë¡œ ê³ ìœ  í•´ì‹œ ìƒì„±"""
        chapters_sorted = sorted(chapters)
        return hashlib.md5(':'.join(chapters_sorted).encode()).hexdigest()[:12]

    async def get_or_setup_context_cache(self, chapters: List[str], strategy):
        """ì¥ ì¡°í•©ë³„ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ í™•ë³´ + ì„¤ì • (ì „ì—­ ìºì‹œ í™œìš©)"""
        chapter_hash = self.generate_chapter_hash(chapters)
        
        # ê¸°ì¡´ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ í™•ì¸ (ì „ì—­ ìºì‹œì—ì„œ)
        if chapter_hash in self.context_cache:
            session_info = self.context_cache[chapter_hash]
            if await self._is_context_cache_valid(session_info):
                # ìºì‹œ ì¬ì‚¬ìš© ìƒì„¸ ë¡œê¹…
                metadata = self.context_metadata[chapter_hash]
                self.logger.info(f"â™»ï¸ ì¥ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ì¬ì‚¬ìš© (í•´ì‹œ: {chapter_hash}) | ì¥: {chapters}")
                self.logger.info(f"   ğŸ“Š ìºì‹œ ì •ë³´: ìƒì„±ì‹œê°„={metadata['created_at'].strftime('%H:%M:%S')}, ì‚¬ìš©íšŸìˆ˜={metadata['usage_count']}")
                
                # ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
                self.context_metadata[chapter_hash]["last_used"] = datetime.now()
                self.context_metadata[chapter_hash]["usage_count"] += 1
                
                return session_info

        # ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ìƒì„± 
        session_info = await self.ai_service.create_session()
        
        # âœ… í•µì‹¬: ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (í•œ ë²ˆë§Œ!)
        await self._setup_chapter_context(session_info, strategy)
        
        # ì „ì—­ ìºì‹œì— ì €ì¥
        self.context_cache[chapter_hash] = session_info
        self.context_metadata[chapter_hash] = {
            "created_at": datetime.now(),
            "last_used": datetime.now(), 
            "chapters": chapters,
            "usage_count": 1
        }
        
        self.logger.info(f"ğŸ†• ìƒˆ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ìƒì„± (í•´ì‹œ: {chapter_hash}) | ì¥: {chapters}")
        self.logger.info(f"   ğŸ’¾ ì „ì—­ ìºì‹œ í†µê³„: ì´ {len(self.context_cache)}ê°œ ìºì‹œ ë³´ìœ ")
        return session_info

    async def _setup_chapter_context(self, session_info, strategy):
        """ì»¨í…ìŠ¤íŠ¸ ìºì‹œì— ì¥ ë‚´ìš© ì„¤ì • (í•œ ë²ˆë§Œ ì‹¤í–‰)"""
        # ì¥ content ë¡œë“œ
        contents = []
        book_path = Path(self.config.config.base_data_path) / strategy.book_name
        
        for chapter_id in strategy.target_chapters:
            chapter_content_file = book_path / chapter_id / "content.md"
            if chapter_content_file.exists():
                with open(chapter_content_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    contents.append(f"# {chapter_id}\n{content}")

        combined_content = "\n\n".join(contents)
        
        # âœ… ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ ì„¤ì • í”„ë¡¬í”„íŠ¸
        context_setup_prompt = f"""ë‹¤ìŒì€ ì°¸ì¡°í•  ì¥ë“¤ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´í›„ ì§ˆì˜ì—ì„œëŠ” ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

{combined_content}

**ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™:**
1. ì´ ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ìˆë‹¤ê°€, ë‹¤ìŒ ì§ˆì˜ë“¤ì— ëŒ€í•´ ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
2. ì»¨í…ì¸ ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
3. **ë‹µë³€ ìƒì„± ì‹œ ë°˜ë“œì‹œ ì°¸ì¡°í•œ ì„¹ì…˜ëª…ê³¼ ì¤„ ë²ˆí˜¸ ì •ë³´ë¥¼ ë‹µë³€ ëì— í‘œì‹œí•´ì£¼ì„¸ìš”.**
   í˜•ì‹: [ì°¸ì¡°: ì„¹ì…˜ëª… (ì¤„ XX-XX)]"""

        # âœ… ì˜¬ë°”ë¥¸ ë©”ì„œë“œëª… ì‚¬ìš©
        await self.ai_service.query_with_persistent_session(context_setup_prompt, session_info)

    async def query_with_cached_context(self, query: str, session_info) -> str:
        """ìºì‹œëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì§ˆì˜ (ì§ˆì˜ë§Œ ì „ì†¡!)"""
        # âœ… í•µì‹¬: ì§ˆì˜ë§Œ ì „ì†¡ (ì»¨í…ìŠ¤íŠ¸ëŠ” ì´ë¯¸ ìºì‹œì— ìˆìŒ)
        simple_query = f"ì§ˆì˜: {query}"
        
        self.logger.info(f"ğŸ¤– ìºì‹œëœ ì»¨í…ìŠ¤íŠ¸ë¡œ AI ì§ˆì˜ ì‹¤í–‰ ì¤‘...")
        self.logger.info(f"   ğŸ“ ì§ˆì˜ ê¸¸ì´: {len(simple_query)}ì")
        
        # âœ… ì˜¬ë°”ë¥¸ ë©”ì„œë“œëª… ì‚¬ìš©
        response = await self.ai_service.query_with_persistent_session(simple_query, session_info)
        
        self.logger.info(f"âœ… AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(response)}ì)")
        return response

    async def _is_context_cache_valid(self, session_info) -> bool:
        """ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ìœ íš¨ì„± ê²€ì¦"""
        try:
            # SessionInfo ê°ì²´ì˜ ìœ íš¨ì„± í™•ì¸
            return session_info is not None and hasattr(session_info, 'session_data')
        except:
            return False

    async def cleanup_expired_caches(self):
        """ë§Œë£Œëœ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ì •ë¦¬"""
        now = datetime.now()
        expired_hashes = []
        
        for hash_key, metadata in self.context_metadata.items():
            if now - metadata["created_at"] > timedelta(seconds=self.global_cache.cache_ttl):
                expired_hashes.append(hash_key)

        for hash_key in expired_hashes:
            if hash_key in self.context_cache:
                del self.context_cache[hash_key]
            if hash_key in self.context_metadata:
                del self.context_metadata[hash_key]

        if expired_hashes:
            self.logger.info(f"ğŸ§¹ ë§Œë£Œëœ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ì •ë¦¬: {len(expired_hashes)}ê°œ")
            
    def get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„ ì •ë³´ ë°˜í™˜"""
        return {
            "total_caches": len(self.context_cache),
            "cache_usage": {hash_key: metadata["usage_count"] for hash_key, metadata in self.context_metadata.items()},
            "cache_age": {hash_key: (datetime.now() - metadata["created_at"]).seconds for hash_key, metadata in self.context_metadata.items()}
        }