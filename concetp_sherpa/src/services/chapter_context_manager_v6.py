# ìƒì„± ì‹œê°„: 2024-09-20 00:05:00 KST  
# í•µì‹¬ ë‚´ìš©: ì‹¬í”Œ íŒŒì¼ ê¸°ë°˜ Chapter ì»¨í…ìŠ¤íŠ¸ ìºì‹± ë§¤ë‹ˆì € (ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥)
# ìƒì„¸ ë‚´ìš©:
#   - SimpleFileCache (ë¼ì¸ 20-60): ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥í•˜ëŠ” íŒŒì¼ ìºì‹œ
#   - ChapterContextManager (ë¼ì¸ 65-150): ì„¸ì…˜ ì¬ìƒì„± ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € 
#   - _is_cache_valid (ë¼ì¸ 155-170): ìºì‹œ ìœ íš¨ì„± ê²€ì¦
#   - _setup_chapter_context (ë¼ì¸ 175-195): ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
# ìƒíƒœ: active
# ì°¸ì¡°: chapter_context_manager_v5.py (ì§ë ¬í™” ë¬¸ì œ í•´ê²°)

import hashlib
import asyncio
import json
import time
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from pathlib import Path

class SimpleFileCache:
    """ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥í•˜ëŠ” ê°„ë‹¨í•œ íŒŒì¼ ìºì‹œ"""
    
    def __init__(self, cache_dir: str = None):
        if cache_dir is None:
            cache_dir = Path(__file__).parent.parent.parent / "cache" / "chapter_contexts"
        
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_ttl = 3600  # 1ì‹œê°„ TTL
    
    def _get_metadata_file_path(self, chapter_hash: str) -> Path:
        """ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ"""
        return self.cache_dir / f"metadata_{chapter_hash}.json"
    
    def save_metadata(self, chapter_hash: str, metadata: dict):
        """ë©”íƒ€ë°ì´í„°ë§Œ íŒŒì¼ì— ì €ì¥"""
        try:
            metadata_file = self._get_metadata_file_path(chapter_hash)
            
            # datetime ê°ì²´ë¥¼ timestampë¡œ ë³€í™˜
            serializable_metadata = {}
            for key, value in metadata.items():
                if isinstance(value, datetime):
                    serializable_metadata[key] = value.timestamp()
                else:
                    serializable_metadata[key] = value
            
            cache_data = {
                "chapter_hash": chapter_hash,
                "metadata": serializable_metadata,
                "saved_at": time.time()
            }
            
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ (í•´ì‹œ: {chapter_hash}): {e}")
    
    def load_metadata(self, chapter_hash: str) -> Optional[dict]:
        """íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            metadata_file = self._get_metadata_file_path(chapter_hash)
            
            if not metadata_file.exists():
                return None
            
            with open(metadata_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # TTL í™•ì¸
            saved_at = cache_data.get("saved_at", 0)
            if time.time() - saved_at > self.cache_ttl:
                # ë§Œë£Œëœ íŒŒì¼ ì‚­ì œ
                metadata_file.unlink(missing_ok=True)
                return None
            
            # timestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
            metadata = cache_data["metadata"]
            for key, value in metadata.items():
                if key in ['created_at', 'last_used'] and isinstance(value, (int, float)):
                    metadata[key] = datetime.fromtimestamp(value)
            
            return metadata
            
        except Exception as e:
            print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ (í•´ì‹œ: {chapter_hash}): {e}")
            return None
    
    def update_metadata(self, chapter_hash: str, metadata_updates: dict):
        """ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸"""
        existing_metadata = self.load_metadata(chapter_hash)
        if existing_metadata:
            existing_metadata.update(metadata_updates)
            self.save_metadata(chapter_hash, existing_metadata)
    
    def cleanup_expired_metadata(self):
        """ë§Œë£Œëœ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì •ë¦¬"""
        if not self.cache_dir.exists():
            return
            
        metadata_files = list(self.cache_dir.glob("metadata_*.json"))
        expired_count = 0
        
        for metadata_file in metadata_files:
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                
                saved_at = cache_data.get("saved_at", 0)
                if time.time() - saved_at > self.cache_ttl:
                    metadata_file.unlink(missing_ok=True)
                    expired_count += 1
                    
            except Exception as e:
                print(f"âš ï¸ ë§Œë£Œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {metadata_file} - {e}")
        
        if expired_count > 0:
            print(f"ğŸ§¹ ë§Œë£Œëœ ë©”íƒ€ë°ì´í„° íŒŒì¼ ì •ë¦¬: {expired_count}ê°œ")
    
    def get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„"""
        if not self.cache_dir.exists():
            return {"metadata_files": 0}
            
        metadata_files = len(list(self.cache_dir.glob("metadata_*.json")))
        return {"metadata_files": metadata_files}

class ChapterContextManager:
    """ì„¸ì…˜ ì¬ìƒì„± ê¸°ë°˜ ì¥ ì¡°í•©ë³„ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    
    def __init__(self, ai_service, logger, config_manager):
        self.ai_service = ai_service
        self.logger = logger
        self.config = config_manager
        
        # ë©”íƒ€ë°ì´í„°ë§Œ ì €ì¥í•˜ëŠ” íŒŒì¼ ìºì‹œ
        self.file_cache = SimpleFileCache()
        
        # ë©”ëª¨ë¦¬ ë‚´ ì„¸ì…˜ ìºì‹œ (í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ ìœ íš¨)
        self.session_cache: Dict[str, Any] = {}  # {chapter_hash: session_info}

    def generate_chapter_hash(self, chapters: List[str]) -> str:
        """ì¥ ì¡°í•©ìœ¼ë¡œ ê³ ìœ  í•´ì‹œ ìƒì„±"""
        chapters_sorted = sorted(chapters)
        return hashlib.md5(':'.join(chapters_sorted).encode()).hexdigest()[:12]

    async def get_or_setup_context_cache(self, chapters: List[str], strategy):
        """ì¥ ì¡°í•©ë³„ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ í™•ë³´ + ì„¤ì •"""
        chapter_hash = self.generate_chapter_hash(chapters)
        
        # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸ (í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì´ë¯¸ ìƒì„±ëœ ì„¸ì…˜)
        if chapter_hash in self.session_cache:
            session_info = self.session_cache[chapter_hash]
            if await self._is_context_cache_valid(session_info):
                self.logger.info(f"â™»ï¸ ë©”ëª¨ë¦¬ ìºì‹œ ì¬ì‚¬ìš© (í•´ì‹œ: {chapter_hash}) | ì¥: {chapters}")
                
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                self.file_cache.update_metadata(chapter_hash, {
                    "last_used": datetime.now(),
                    "usage_count": self.file_cache.load_metadata(chapter_hash).get("usage_count", 0) + 1
                })
                
                return session_info
        
        # 2. íŒŒì¼ ë©”íƒ€ë°ì´í„° í™•ì¸ (ì´ì „ í”„ë¡œì„¸ìŠ¤ì—ì„œ ìƒì„±ëœ ìºì‹œ ì •ë³´)
        metadata = self.file_cache.load_metadata(chapter_hash)
        if metadata:
            # ì´ì „ì— ê°™ì€ ì¥ ì¡°í•©ì´ ì²˜ë¦¬ë˜ì—ˆìŒì„ í™•ì¸
            self.logger.info(f"ğŸ“‚ ì´ì „ ì„¸ì…˜ ê¸°ë¡ ë°œê²¬ (í•´ì‹œ: {chapter_hash}) | ì¥: {chapters}")
            created_time = metadata['created_at'].strftime('%H:%M:%S')
            self.logger.info(f"   ğŸ“Š ì´ì „ ìºì‹œ ì •ë³´: ìƒì„±ì‹œê°„={created_time}, ì‚¬ìš©íšŸìˆ˜={metadata['usage_count']}")
            
            # ìƒˆ ì„¸ì…˜ ìƒì„±í•˜ì§€ë§Œ, ê°™ì€ ì»¨í…ìŠ¤íŠ¸ë¡œ ë¹ ë¥´ê²Œ ì„¤ì • ê°€ëŠ¥
            self.logger.info(f"ğŸ”„ ë™ì¼ ì¥ ì¡°í•©ìœ¼ë¡œ ìƒˆ ì„¸ì…˜ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ ì¬ì„¤ì •)")
        
        # 3. ìƒˆ ì„¸ì…˜ ìƒì„± + ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
        session_info = await self.ai_service.create_session()
        await self._setup_chapter_context(session_info, strategy)
        
        # 4. ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
        self.session_cache[chapter_hash] = session_info
        
        # 5. ë©”íƒ€ë°ì´í„° ì €ì¥/ì—…ë°ì´íŠ¸
        if metadata:
            # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            metadata_updates = {
                "last_used": datetime.now(),
                "usage_count": metadata["usage_count"] + 1
            }
            self.file_cache.update_metadata(chapter_hash, metadata_updates)
            log_message = f"ğŸ”„ ì¥ ì¡°í•© ì¬ì²˜ë¦¬ (í•´ì‹œ: {chapter_hash}) | ì¥: {chapters}"
        else:
            # ìƒˆ ë©”íƒ€ë°ì´í„° ìƒì„±
            new_metadata = {
                "created_at": datetime.now(),
                "last_used": datetime.now(), 
                "chapters": chapters,
                "usage_count": 1
            }
            self.file_cache.save_metadata(chapter_hash, new_metadata)
            log_message = f"ğŸ†• ìƒˆ ì¥ ì¡°í•© ì²˜ë¦¬ (í•´ì‹œ: {chapter_hash}) | ì¥: {chapters}"
        
        self.logger.info(log_message)
        cache_stats = self.file_cache.get_cache_stats()
        self.logger.info(f"   ğŸ’¾ ìºì‹œ í†µê³„: ë©”ëª¨ë¦¬ {len(self.session_cache)}ê°œ, ë©”íƒ€ë°ì´í„° {cache_stats['metadata_files']}ê°œ")
        
        return session_info

    async def _setup_chapter_context(self, session_info, strategy):
        """ì»¨í…ìŠ¤íŠ¸ ìºì‹œì— ì¥ ë‚´ìš© ì„¤ì •"""
        # ì¥ content ë¡œë“œ
        contents = []
        book_path = Path(self.config.config.base_data_path) / strategy.book_name
        
        for chapter_id in strategy.target_chapters:
            chapter_content_file = book_path / chapter_id / "content.md"
            if chapter_content_file.exists():
                with open(chapter_content_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    contents.append(f"# {chapter_id}\n{content}")

        combined_content = "\n\n".join(contents)
        
        context_setup_prompt = f"""ë‹¤ìŒì€ ì°¸ì¡°í•  ì¥ë“¤ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´í›„ ì§ˆì˜ì—ì„œëŠ” ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

{combined_content}

**ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™:**
1. ì´ ë‚´ìš©ì„ ê¸°ì–µí•˜ê³  ìˆë‹¤ê°€, ë‹¤ìŒ ì§ˆì˜ë“¤ì— ëŒ€í•´ ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
2. ì»¨í…ì¸ ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
3. **ë‹µë³€ ìƒì„± ì‹œ ë°˜ë“œì‹œ ì°¸ì¡°í•œ ì„¹ì…˜ëª…ê³¼ ì¤„ ë²ˆí˜¸ ì •ë³´ë¥¼ ë‹µë³€ ëì— í‘œì‹œí•´ì£¼ì„¸ìš”.**
   í˜•ì‹: [ì°¸ì¡°: ì„¹ì…˜ëª… (ì¤„ XX-XX)]"""

        await self.ai_service.query_with_persistent_session(context_setup_prompt, session_info)

    async def query_with_cached_context(self, query: str, session_info) -> str:
        """ìºì‹œëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì§ˆì˜"""
        simple_query = f"ì§ˆì˜: {query}"
        
        self.logger.info(f"ğŸ¤– ì»¨í…ìŠ¤íŠ¸ë¡œ AI ì§ˆì˜ ì‹¤í–‰ ì¤‘...")
        self.logger.info(f"   ğŸ“ ì§ˆì˜ ê¸¸ì´: {len(simple_query)}ì")
        
        response = await self.ai_service.query_with_persistent_session(simple_query, session_info)
        
        self.logger.info(f"âœ… AI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(response)}ì)")
        return response

    async def _is_context_cache_valid(self, session_info) -> bool:
        """ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ìœ íš¨ì„± ê²€ì¦"""
        try:
            return session_info is not None and hasattr(session_info, 'session_data')
        except:
            return False

    def cleanup_expired_caches(self):
        """ë§Œë£Œëœ ìºì‹œ ì •ë¦¬"""
        self.file_cache.cleanup_expired_metadata()
        
    def get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„ ì •ë³´"""
        file_stats = self.file_cache.get_cache_stats()
        return {
            "memory_sessions": len(self.session_cache),
            "metadata_files": file_stats["metadata_files"]
        }