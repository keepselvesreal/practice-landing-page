# 13.1 AI Isn’t Going Away (pp.245-246)

---
**Page 245**

CHAPTER 13
Keeping AI Honest with Unit Tests
You’ve learned a number of benefits you can gain from writing unit tests:
fewer defects, of course, but also trustworthy documentation, the ability to
keep your code clean through refactoring, and a dramatic increase in confi-
dence for shipping the system.
AI can generate code, creating increasingly dramatic implications for the
software development industry and you. Yet, unit testing can and will provide
tremendous value in your software development efforts. In this chapter, you’ll
take an approach involving AI generation of both production code and unit
tests. You’ll discover why unit tests remain essential, and you’ll learn how to
incorporate them into a workflow that will give you the confidence to ship.
AI Isn’t Going Away
By the time you read this chapter, the capabilities of artificial intelligence (AI)
will have advanced, perhaps significantly, from when I wrote it (January
2024). At some future point, very possibly within the span of your career,
most (not all) software will be generated by AI.
You will still need to tell your AI assistant what to do.
Today, AI-generated code has limitations. It’s of dubious quality, for one—very
stepwise and highly concrete. Maybe when AI evolves to a point where the
code always works as expected, its quality won’t matter because, at that point,
you might never have to read or write another word of code again. But today,
AI-generated code may contain defects. ChatGPT, for example, perpetually
admits that fact:
ChatGPT can make mistakes. Consider checking important information.
I’ve seen failures often occur when an LLM (Large Language Model) adds a
new feature to an existing body of code, for example. You’ll explore how to
report erratum  •  discuss


---
**Page 246**

help your LLM do a better job with that challenge in this chapter. But left to
its own devices, an LLM is increasingly likely to break existing functionality
as it adds new increments.
Do not trust any AI-generated code to be correct.
I’ve been pleasantly surprised, though: more often than not, the code LLMs
(including ChatGPT, Meta.ai, and Claude) have produced for me has been
correct. But I’ve also seen them generate enough wrong code to know that I
could never fully depend on it.
From these limitations arises a critical need: if you’re going to use AI tools to
generate code, you’ll need to create and run tests.
Fortunately, you’ve read the rest of this book (right?) and know how to do
just that. Even better, AI will speed you up by coding the tests.
Give the benefit of the doubt to your pair programmer—whether artificial or
human—but assume that you can both make mistakes. доверяй, но проверяй.
(“Trust, but verify.”)
Note: as I write this, you can also use tools like GitHub Copilot, JetBrains AI
Assistant, and Duet to help you develop. These tools sit atop one or more
LLMs and provide what can best be described as AI-assisted code completion.
I highly recommend incorporating them into your regular code development
process. In this chapter, however, you’ll focus on using a test-driven process
for generating code at the class level—with the intent of maximizing the
amount of (verified) code that AI can generate for you.
Exploring a Simple Example with ChatGPT
Interaction with an LLM via prompting is a conversation. That conversation
may play out very differently the next time I have it. As a result, it’s probably
best if this chapter reads as a story about my personal interaction with
ChatGPT on a small example. Accordingly, unlike the rest of the book, this
chapter is written in first-person past tense.
I held my conversation with OpenAI’s chatbot, ChatGPT, which at the time
was based on the GPT-4 LLM. My subsequent mentions of ChatGPT refer to
this configuration. While other models may exist that have been trained to be
optimized for programming tasks (Code Llama for example), the experience I
Chapter 13. Keeping AI Honest with Unit Tests • 246
report erratum  •  discuss


